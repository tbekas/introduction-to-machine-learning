{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definition of Machine Learning\n",
    "*Field of study that gives computers the ability to learn without being explicitly programmed. Arthur Samuel (1959)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised learning\n",
    "For every given input we know how correct output should look like.\n",
    "### Examples\n",
    "* Given data about the size of houses on the real estate market, try to predict their price.\n",
    "* Given an email content, we would like to classify it either as spam or not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised learning\n",
    "For set of inputs we're trying to find the structure or relationships between different inputs.\n",
    "### Example\n",
    "* Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised learning example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## House pricing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"helper.jl\")\n",
    "m = 10\n",
    "X, y = gen_samples(m)\n",
    "\n",
    "[X y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_samples(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Single variable\n",
    "\\begin{equation*}\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1 x\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple variables\n",
    "\\begin{equation*}\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple variables - vector notation\n",
    "\\begin{equation*}\n",
    "h_{\\theta}(x) = x \\cdot \\Theta\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x = \\left[1\\ x_1\\ x_2\\ \\cdots\\ x_n \\right],\n",
    "\\Theta = \\begin{bmatrix}\n",
    "       \\theta_0 \\\\\n",
    "       \\theta_1 \\\\\n",
    "       \\theta_2 \\\\\n",
    "       \\vdots \\\\\n",
    "       \\theta_n\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose $\\theta_0$, $\\theta_1$ so that $h_{\\theta}(x)$ is close to $y$ for our training examples $(x,y)$\n",
    "\n",
    "\\begin{equation*}\n",
    "J(\\theta_0, \\theta_1)=\\frac{1}{2m}\\sum_{i=1}^{m}\\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right)^2\n",
    "\\end{equation*}\n",
    "\n",
    "$x^{(i)}$ and $y^{(i)}$ denotes the i-th example in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "_X=[ones(m, 1) X]\n",
    "\n",
    "J(Θ) = 1/2m .* sum(((_X * Θ) - y).^2)\n",
    "\n",
    "plot_cost(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cost optimization (TODO: add derivatives here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent algorithm\n",
    "`repeat for every` $j=0,\\dots,n$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_j:=\\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J\\left(\\theta_0,\\dots,\\theta_n\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "`end repeat`\n",
    "\n",
    "$\\alpha$ denotes the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 10.0^-4\n",
    "Θ = [0.0, 0.0]\n",
    "\n",
    "G(Θ) = 1/m .* _X' * (_X * Θ - y)\n",
    "\n",
    "for i=1:10^6\n",
    "    Θ = Θ - α * G(Θ)\n",
    "end\n",
    "\n",
    "Θ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "\n",
    "init_Θ=[0.0, 0.0]\n",
    "\n",
    "G!(res, Θ) = res[:] = G(Θ)\n",
    "\n",
    "optimize(J, G!, init_Θ, GradientDescent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why linear regression is not suitable for classification problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1]\n",
    "plot(X, y, \"rx\")\n",
    "plot(X, 1/6 .* (X .- 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 14]\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "plot(X, y, \"rx\")\n",
    "plot(X, 1/10 .* (X .- 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of logistic regression\n",
    "\\begin{equation*}\n",
    "h_{\\theta}(x) = s(\\Theta^Tx)\\\\\n",
    "s(z)=\\frac{1}{1+e^{-z}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig(z) = 1.0 ./ (1.0 .+ exp.(-z))\n",
    "\n",
    "sig([-10, -1, 0, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = range(-5,stop=5,length=100)\n",
    "plot(z, sig(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Installing required dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "\n",
    "X, y = MNIST.traindata();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "size(X), size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(minimum(X), maximum(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Displaying individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Interact\n",
    "\n",
    "w, h, m = size(X)\n",
    "\n",
    "f_img = figure(figsize=(5,5))\n",
    "@manipulate throttle = 0.5 for i = 1:m\n",
    "    withfig(f_img) do;\n",
    "        imshow(X[:,:,i]', cmap=\"gray\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Training is done only on 300 out of 30000 examples available in the MNIST dataset. To increase size of the training dataset modify the `_m` variable - note that the training time will increase as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "\n",
    "_n = w * h\n",
    "_m = 300\n",
    "_X = X[:, :, 1:_m]\n",
    "_X = reshape(_X, (_n, _m))'\n",
    "_X = [ones(_m, 1) _X]\n",
    "init_Θ = zeros(_n+1)\n",
    "λ = 0.1\n",
    "all_Θ = zeros(10, _n+1)\n",
    "\n",
    "for i = 1:10\n",
    "    println(\"iteration $i/10\")\n",
    "    \n",
    "    @time begin\n",
    "        _y = y[1:_m] .== i % 10\n",
    "\n",
    "        local J(Θ) = (-_y' * log.(sig(_X * Θ)) .- (1.0 .- _y') * log.(1 .- sig(_X * Θ)))[1] .+ λ/2_m * sum(Θ[2:end] .^ 2)\n",
    "        local G(Θ) = 1/_m .* _X' * (sig(_X * Θ) .- _y) + pushfirst!(λ/_m * Θ[2:end], 0.0)\n",
    "        local G!(res, Θ) = res[:] = G(Θ)\n",
    "\n",
    "        res = optimize(J, G!, init_Θ, GradientDescent())\n",
    "        all_Θ[i,:] = res.minimizer\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions based on trained model\n",
    "\n",
    "Move the slider to check how the trained model predicts the number in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = figure(figsize=(10,10))\n",
    "@manipulate throttle = 0.5 for i = 1:m\n",
    "    withfig(f) do;\n",
    "        subplot(211)\n",
    "        bar(1:10,reshape(sig([1 X[:,:,i]...] * all_Θ'), 10))\n",
    "        subplot(212)\n",
    "        axis(\"off\")\n",
    "        imshow(X[:,:,i]', cmap=\"gray\")\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "444b199f3b5745c88236b8f452661802",
   "lastKernelId": "5ce9d33f-0d8d-4d94-96d2-2408bbc05259"
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
